目标是简洁、可靠、高效

基本原则：离线维护数据，数据实时同步至生产环境
文件传输方式：Linux文件同步命令，并加上相应的数据校验

现在字典数据增长有三个不同的来源方式：
1、用户在店铺管理后台增加数据 （数据单条增加，有可能填写的数据不建全）
2、用户上传SDF文档  （数据批量增加）
3、抓取数据批量导入  (字典数据批量增加)


表增加create_time字段，便于检查是否有新增数据

图片路径问题:
修改图片路径，以yyyy-MM-dd/001/001/0001/1.jpg的方式存储相应的图片，便于复制／备份和维护

可能遇到的问题：!!!  
因为目前在数据表上,cas号并不是必填数据。
这样会存在以下的问题：
如果用户A填写了产品A1的一个错误结构式，并添加了相应的商品。用户B填写了产品的B1的一个正确的结构式，并添加了相应的商品。
其实A1和B1指向的是同一个结构式。如果用户修正结构式数据，必然导致字典库中会有同一个产品的两条记录？这种情况如何处理，请考虑之。

search_moldata表精简问题：
is_audit
is_user_add

字典数据校检脚本：
为了保证字典数据的准确性，我将以search_moldata表为基准对其它表的数据进行相应的校验，发现数据错误，会进行相应的修正。

图片文件夹的命名:


数据离线维护的方式：


10上程序启动脚本(日志的导出目录区分程序运行的是那个环境的):
nohup python /usr/local/python_tool/dict_data_prod/dict_worker_v2.py --logfile=/newdata2/log/dict_worker/dict_worker_prod.log>/dev/null &
python dict_worker_v2.py --logfile=/newdata2/log/dict_worker/dict_worker_dev.log


正式环境启动指令:
启动命令: 
cd /opt/molbase.inc/dic_do/python_tool/dict_data
nohup python2.7 dict_agent.py --logfile=/opt/molbase.inc/log/dict_agent.log > /dev/null &

